# 推荐算法
## 1. Content base
### 1.1 原理：
分为基于用户的内容推荐和基于物品的内容推荐，分别是根据用户的特征信息，给相似的用户推荐物品和基于物品的特征信息，给用户推荐相似的物品
### 1.2 优点和缺点：
优点：
（1）不需要其他的用户数据，基于某一个用户的数据，进行挖掘就可以得到
（2）能够满足某个用户的单一爱好，不会推荐出不相关的item
（3）能够推荐一些不是很热门，但是很新的item
（4）对于推荐系统来说，能够很好的解释推荐原因
缺点：
（1）推荐物品过分单一，不够多样性，覆盖率低
（2）很难找到精确的物品
（3）冷启动问题，无法马上对新用户进行推荐

## 2. 协同过滤
### 3.1 基于近邻的协同过滤
分为基于用户的协同过滤(User-CF)和基于物品的协同过滤(Item-CF)，可以看做用户对物品有一个打分行为，通过对打分行为的相似度进行挖掘，为用户进行推荐

### 3.2 基于模型的协同过滤
#### 3.2.1 奇异值分解
优点：一步到位，直接得到最优解，缺点：直接使用SVD复杂度太高$O(n^3)$
#### 3.2.2 潜在语义分析
同是矩阵分解，但是优化方式不同，交替最小二乘法(ALS) 和梯度下降法
假定有U个用户和D个物品，R为打分矩阵，K个隐含变量，则我们需要找到矩阵$P(U*K)$和$Q(D*K)$
使得$R \approx \hat R = PQ^T$ 其中$\hat r_{ij}=\sum_{k=1}^kp_{ik}q_{kj}$
目标：找到最优的$P$和$Q$
梯度下降法：
（1）定义损失函数$e_{ij}^{2}= (r_{ij}-\hat r_{ij})^2$
（2）求解梯度，分别对P和Q求偏导
（3）迭代更新，同时更新矩阵P和Q的元素值
迭代更新一定次数后，$\hat R$与原矩阵相比会发现原矩阵的缺省值在预测矩阵中的值为0，类似于ML中的过拟合，因此要在损失函数中添加正则化项，并且限定P和Q中的元素是非负的，因为负值元素是不可解释的。

## 4. 相似度度量方法
### 4.1 余弦相似度
$$
sim_{cos}(u,v)= \frac{\sum_{i\in I_{u,v}}r_{u,i}r_{v,i}}{\sqrt{\sum_{i\in I_{u,v}}r_{u,i}^2}\sqrt{\sum_{i\in I_{u,v}}r_{v,i}^2}}
$$
$I_{u,v}$---用户$u$和用户$v$的共同评分项目集
$r_{u,i}$和$r_{v,i}$---分别表示用户$u$和用户$v$的对项目i的评分
余弦相似度通过两个向量的夹角余弦值来度量相似度，两个向量的夹角越小，其夹角的余弦值越大，则余弦相似度越高。这种方式对评分数值不敏感，尽管两个用户的评分差很大，但是相似度也很大。余弦相似度过度关注向量之间的夹角而忽视了向量的长度（共同评分的数量），而且过度依赖两个用户的共同评分
### 4.2 修正余弦相似度
$$
sim_{cos}(u,v)= \frac{\sum_{i\in I_{u,v}}(r_{u,i}-\overline{r_{u}})(r_{v,i}-\overline{r_{v}})}{\sqrt{\sum_{i\in I_{u,v}}(r_{u,i}-\overline{r_{u}})^2}\sqrt{\sum_{i\in I_{u,v}}(r_{v,i}-\overline{r_{v}})^2}}
$$
$\overline{r_{u}}$ ---用户$u$的平均评分
$\overline{r_{v}}$ ---用户$v$的平均评分
### 4.3 Person相似度
### 4.4 jaccard相似度